{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>ALPAR - Governo Digital - Processo Inteligente</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>recomendação de ações - gravando em MySQL</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:19.806555Z",
     "start_time": "2021-05-04T21:06:19.035114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas versão 1.3.3\n",
      "numpy versão 1.20.3\n",
      "csv versão 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import csv\n",
    "import codecs\n",
    "import time\n",
    "from os.path import expanduser\n",
    "import sqlite3\n",
    "\n",
    "print(\"pandas versão\", pd.__version__)\n",
    "print(\"numpy versão\", np.__version__)\n",
    "print(\"csv versão\", csv.__version__)\n",
    "\n",
    "pd.options.display.max_rows = 2000\n",
    "pd.options.display.width = 120\n",
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='black'>trata o dataset total</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escolhe o ambiente operacional\n",
    "WIN  = True\n",
    "\n",
    "# localização dos arquivos\n",
    "if WIN:\n",
    "    path_db       = 'C:/Users/Administrator/data-export/'\n",
    "else:\n",
    "    path_db       = '/Users/efz/DADOS_ALPAR_GD/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escolhe qual ambiente será carregado\n",
    "# {'chave': ('nome do ambiente', 'in', 'out')}\n",
    "ambientes = {\n",
    "    0: ('produção',        'bd_fontes.sqlite',     'bd_reco.sqlite'),\n",
    "    1: ('homologação',     'bd_fontes_hom.sqlite', 'bd_reco_hom.sqlite'),\n",
    "    2: ('desenvolvimento', 'bd_fontes_dev.sqlite', 'bd_reco_dev.sqlite'),\n",
    "    3: ('simulação',       'bd_fontes_sim.sqlite', 'bd_reco_sim.sqlite'),\n",
    "} \n",
    "\n",
    "# selecione o banco em questão\n",
    "amb = 1\n",
    "\n",
    "ARQ_SQLITE       = ambientes[amb][1]\n",
    "ARQ_SQLITE_RECO  = ambientes[amb][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tr_tasks_Antigo(df):\n",
    "    tr = {\n",
    "    'protocolo'                   :'protocolo',\n",
    "    'entidade'                    :'entidade',\n",
    "    'entityCode'                  :'Entidade - código',\n",
    "    'servico'                     :'servico',\n",
    "    'usuario'                     :'Usuário',\n",
    "    'grupo'                       :'Grupo',\n",
    "    'data_conclusao'              :'dthr_conclusao',\n",
    "    'data_atendimento'            :'Data e Hora de atendimento',\n",
    "    'data_criacao'                :'dthr_criacao',\n",
    "    'acao'                        :'acao',\n",
    "    'encaminhado_para'            :'encaminhado_para',\n",
    "    'comentario'                  :'Comentário',\n",
    "    'apoio'                       :'Apoio',\n",
    "    'encerrado'                   :'proc_encerrado',\n",
    "    'cancelado'                   :'proc_cancelado',\n",
    "    'motivo_cancelamento'         :'Motivo de cancelamento',\n",
    "    'notificacao'                 :'Notificação',\n",
    "    'status_externo'              :'Status externo',\n",
    "    'agendamento'                 :'Agendamento',\n",
    "    'data_agendamento'            :'Data de agendamento',\n",
    "    'categoria'                   :'Categoria',\n",
    "    'grupo_responsavel'           :'Grupo responsável',\n",
    "    'prazo'                       :'Prazo (em segundos)',\n",
    "    }\n",
    "    return df.rename(columns=tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le_Dataset_SQLITE - Lendo tabelas do SQLITE... tasks=(263, 26) OK\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(path_db + ARQ_SQLITE)\n",
    "\n",
    "# lê tabelas sqlite\n",
    "print('Le_Dataset_SQLITE - Lendo tabelas do SQLITE...', end=' ')\n",
    "sql_tasks   = (\"SELECT * FROM tasks\")\n",
    "\n",
    "df_tasks   = pd.read_sql(sql_tasks,   conn, coerce_float=False)\n",
    "\n",
    "df_tasks   = Tr_tasks_Antigo(df_tasks)\n",
    "\n",
    "print(f'tasks={df_tasks.shape} OK')\n",
    "\n",
    "# fechar a conexão\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.033081Z",
     "start_time": "2021-05-04T21:06:20.014627Z"
    }
   },
   "outputs": [],
   "source": [
    "# coloca null em todas as colunas com dados vazios ou null\n",
    "df_tasks['dthr_conclusao'] = df_tasks['dthr_conclusao'].replace(['null', '', '-'], np.nan)\n",
    "df_tasks['proc_encerrado'] = df_tasks['proc_encerrado'].replace(['null', 'undefined'], 'false')\n",
    "df_tasks['proc_cancelado'] = df_tasks['proc_cancelado'].replace(['null', 'undefined'], 'false')\n",
    "\n",
    "# transforma datas do tipo string para tipo data\n",
    "df_tasks['dthr_conclusao'] = pd.to_datetime(df_tasks['dthr_conclusao'])\n",
    "df_tasks['dthr_criacao']   = pd.to_datetime(df_tasks['dthr_criacao'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.052199Z",
     "start_time": "2021-05-04T21:06:20.034829Z"
    }
   },
   "outputs": [],
   "source": [
    "# verifica a situação de cada protocolo\n",
    "df = df_tasks[['protocolo', 'proc_encerrado', 'proc_cancelado']].copy()\n",
    "\n",
    "df.loc[df['proc_encerrado'] == 'false', 'proc_encerrado'] = 0\n",
    "df.loc[df['proc_encerrado'] == 'true' , 'proc_encerrado'] = 1\n",
    "df.loc[df['proc_cancelado'] == 'false', 'proc_cancelado'] = 0\n",
    "df.loc[df['proc_cancelado'] == 'true' , 'proc_cancelado'] = 1\n",
    "\n",
    "df['proc_encerrado'] = pd.to_numeric(df['proc_encerrado'])\n",
    "df['proc_cancelado'] = pd.to_numeric(df['proc_cancelado'])\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.064819Z",
     "start_time": "2021-05-04T21:06:20.056837Z"
    }
   },
   "outputs": [],
   "source": [
    "# agrupa por protocolo, obtem o máximo de encerrado e cancelado\n",
    "df = df.groupby('protocolo').agg({'proc_encerrado': 'max', 'proc_cancelado': 'max'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.087733Z",
     "start_time": "2021-05-04T21:06:20.068189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0)\n",
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "# filtra os protocolos cancelados\n",
    "df.drop(df[df['proc_cancelado'] == 1].index, inplace=True)\n",
    "\n",
    "# exclui a coluna de protocolos cancelados\n",
    "df.drop('proc_cancelado', axis=1, inplace=True)\n",
    "\n",
    "# cria um dataframe de processos encerrados\n",
    "df_ence = df[(df['proc_encerrado'] == 1)].copy()\n",
    "\n",
    "# cria um dataframe de processos em andamento\n",
    "df_anda = df[(df['proc_encerrado'] == 0)].copy()\n",
    "\n",
    "# exclui a coluna encerrado dos 2 dataframes\n",
    "df_ence.drop('proc_encerrado', axis=1, inplace=True)\n",
    "df_anda.drop('proc_encerrado', axis=1, inplace=True)\n",
    "\n",
    "print(df_ence.shape)\n",
    "print(df_anda.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.095262Z",
     "start_time": "2021-05-04T21:06:20.091289Z"
    }
   },
   "outputs": [],
   "source": [
    "# cria o dataframe de encerrados e dataframe de em andamento\n",
    "lst_ence = df_ence.index.tolist()\n",
    "lst_anda = df_anda.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='black'>cria e trata o dataset de protocolos encerrados</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.104029Z",
     "start_time": "2021-05-04T21:06:20.098176Z"
    }
   },
   "outputs": [],
   "source": [
    "# cria dataset de tasks encerradas\n",
    "df_ence = df_tasks[df_tasks['protocolo'].isin(lst_ence)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.112385Z",
     "start_time": "2021-05-04T21:06:20.107644Z"
    }
   },
   "outputs": [],
   "source": [
    "# coloca a string <vazio> nos valores NULL\n",
    "lst_mod = list(df_ence[df_ence['encaminhado_para'].isnull()].index)\n",
    "df_ence.loc[lst_mod, 'encaminhado_para'] = '<Vazio>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.129164Z",
     "start_time": "2021-05-04T21:06:20.114641Z"
    }
   },
   "outputs": [],
   "source": [
    "# ordena por entidade, serviço, protocolo, dt_criação\n",
    "df_ence.sort_values(by = ['entidade', 'servico', 'protocolo', 'dthr_criacao'], inplace = True)\n",
    "\n",
    "# refaz o índice para a nova ordenação\n",
    "df_ence.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.142089Z",
     "start_time": "2021-05-04T21:06:20.133118Z"
    }
   },
   "outputs": [],
   "source": [
    "# calcula a quantidade de dias da ação e exclui as datas de criação e de conclusão\n",
    "df_ence['dias'] = (df_ence['dthr_conclusao'] - df_ence['dthr_criacao']) / np.timedelta64(1, 'D')\n",
    "df_ence.drop(['dthr_conclusao', 'dthr_criacao'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.149116Z",
     "start_time": "2021-05-04T21:06:20.144905Z"
    }
   },
   "outputs": [],
   "source": [
    "# exclui colunas não utilizáveis\n",
    "df_ence.drop(['proc_encerrado', 'proc_cancelado'], axis=1, inplace=True)\n",
    "\n",
    "# df_ence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.185236Z",
     "start_time": "2021-05-04T21:06:20.151504Z"
    }
   },
   "outputs": [],
   "source": [
    "# agrupa o dataframe por protocolo, entidade e serviço e cria uma tupla de ações como informação de coluna\n",
    "df_ence = (df_ence.groupby(['protocolo', 'entidade', 'servico'])\n",
    "      .agg(\n",
    "        lst_acao=('acao', lambda x: tuple(x)),\n",
    "        lst_encaminhado=('encaminhado_para', lambda x: tuple(x)),\n",
    "        sum_dias=('dias', sum)).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.201314Z",
     "start_time": "2021-05-04T21:06:20.187514Z"
    }
   },
   "outputs": [],
   "source": [
    "# agrupa o dataframe por protocolo, entidade e serviço e cria uma tupla de ações como informação de coluna\n",
    "df_ence = (df_ence.groupby(['entidade', 'servico', 'lst_acao', 'lst_encaminhado'])\n",
    "      .agg(\n",
    "        media_dias=('sum_dias', 'mean')).reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='black'>cria o dataset de protocolos em andamento</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.211033Z",
     "start_time": "2021-05-04T21:06:20.203950Z"
    }
   },
   "outputs": [],
   "source": [
    "# cria dataset de tasks em andamento\n",
    "df_anda = df_tasks[df_tasks['protocolo'].isin(lst_anda)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.221642Z",
     "start_time": "2021-05-04T21:06:20.213094Z"
    }
   },
   "outputs": [],
   "source": [
    "# exclui colunas não utilizáveis\n",
    "df_anda.drop(['proc_encerrado', 'proc_cancelado', 'dthr_conclusao'], axis=1, inplace=True)\n",
    "\n",
    "# exclui as linhas com a coluna ação NULL\n",
    "# df_anda = df_anda[~df_anda['acao'].isnull()].copy()     # esta linha é para quando ausência de dados for NULL\n",
    "df_anda = df_anda[~(df_anda['acao'] == '')].copy()\n",
    "\n",
    "# df_anda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.234609Z",
     "start_time": "2021-05-04T21:06:20.223868Z"
    }
   },
   "outputs": [],
   "source": [
    "# ordena por entidade, serviço, protocolo, dt_criação\n",
    "df_anda.sort_values(by = ['entidade', 'servico', 'protocolo', 'dthr_criacao'], inplace = True)\n",
    "\n",
    "# refaz o índice para a nova ordenação\n",
    "df_anda.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.260089Z",
     "start_time": "2021-05-04T21:06:20.237026Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# agrupa o dataframe por protocolo, entidade e serviço e cria uma tupla de ações como informação de coluna\n",
    "df_anda = (df_anda.groupby(['protocolo', 'entidade', 'servico'])\n",
    "      .agg(lst_acao=('acao', lambda x: tuple(x)))\n",
    "      .reset_index()).copy()\n",
    "df_anda.sort_values(['entidade', 'servico'], inplace = True)\n",
    "# df_anda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='black'>gera estrutura de recomendações</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.716239Z",
     "start_time": "2021-05-04T21:06:20.261979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total de protocolos a processar = range(0, 0)\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "tot = 0\n",
    "\n",
    "# analisa cada protocolo em andamento\n",
    "# procura a sequência do protocolo em andamento para sugerir o restante da sequência\n",
    "\n",
    "# zera a lista de recomendações\n",
    "lst_reco = []\n",
    "const_max_tempo = 999999999.9\n",
    "tot_anda = range(len(df_anda))\n",
    "# tot_anda = range(1000)\n",
    "print('total de protocolos a processar =', tot_anda)\n",
    "\n",
    "# para cada protocolo em andamento procura uma coleção de sequências dos protocolos encerrados\n",
    "anda_quebra = [None, None]\n",
    "for i in tot_anda:\n",
    "    if anda_quebra != [df_anda.loc[i, 'entidade'], df_anda.loc[i, 'servico']]:\n",
    "        anda_quebra = [df_anda.loc[i, 'entidade'], df_anda.loc[i, 'servico']]\n",
    "        df_aux1 = df_ence[(df_ence['entidade'] == df_anda.loc[i, 'entidade']) & \n",
    "                          (df_ence['servico'] == df_anda.loc[i, 'servico'])]\n",
    "    \n",
    "    n_acoes = len(df_anda.loc[i, 'lst_acao'])\n",
    "    df_aux = df_aux1[(df_aux1['lst_acao'].apply(lambda x: x[:n_acoes]) == df_anda.loc[i, 'lst_acao'])]\n",
    "    \n",
    "    df_aux.reset_index(inplace = True)\n",
    "    \n",
    "    # zera a variável que vai achar o registro \"entidade/serviço\" com o menor tempo de conclusão\n",
    "    # para quando for achado mais de 1 possibilidade\n",
    "    min_tempo = const_max_tempo\n",
    "    dt = {'sequencia': [], 'encaminhamento': []}\n",
    "\n",
    "    qtd_casos = len(df_aux)\n",
    "    tot += qtd_casos\n",
    "        \n",
    "    for k in range(qtd_casos):\n",
    "        valor = round(np.float(df_aux.loc[k, 'media_dias']), 6)\n",
    "        if (valor < min_tempo) or (min_tempo == None):\n",
    "            min_tempo = valor\n",
    "            dt = {'sequencia': list(df_aux.loc[k, 'lst_acao']),\n",
    "                  'encaminhamento': list(df_aux.loc[k, 'lst_encaminhado'])}\n",
    "            \n",
    "    indice = len(list(df_anda.loc[i, 'lst_acao'])) if dt else -1\n",
    "    if qtd_casos == 1:\n",
    "        tipo_recomendacao = 2\n",
    "    elif qtd_casos > 1:\n",
    "        tipo_recomendacao = 3\n",
    "    else:\n",
    "        tipo_recomendacao = 1\n",
    "        \n",
    "    it = {'protocolo': df_anda.loc[i, 'protocolo'],\n",
    "            'seq_atual': list(df_anda.loc[i, 'lst_acao']),\n",
    "            'recomendacao': dt,\n",
    "            'tempo_medio': None if min_tempo == const_max_tempo else min_tempo,\n",
    "            'reco_acao_idx': indice,\n",
    "            'qtd_casos' : qtd_casos,\n",
    "            'tipo_recomendacao' : tipo_recomendacao}\n",
    "    lst_reco.append(it)\n",
    "    if i % 100 == 0:\n",
    "        print(i, tot)\n",
    "\n",
    "# print(i, tot)\n",
    "# print('tempo =', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='black'>cria um arquivo com recomendações</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>CRIA as LISTAS de gravação de protocolos e recomendações no MySQL</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T21:06:20.735778Z",
     "start_time": "2021-05-04T21:06:20.727839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepara uma lista de tuplas para gravação da tabela \"tb_protocolo\" no MySQL\n",
    "lst_protocolo = []\n",
    "lst_recomenda = []\n",
    "for k in lst_reco:\n",
    "    prx_acao = None\n",
    "    prx_encaminhamento = None\n",
    "    \n",
    "    n_acoes_ence = len(k['recomendacao']['sequencia'])\n",
    "    for j in range(n_acoes_ence):\n",
    "        if j == k['reco_acao_idx']:\n",
    "            proximo = 1\n",
    "            prx_acao = k['recomendacao']['sequencia'][j]\n",
    "            prx_encaminhamento = k['recomendacao']['encaminhamento'][j]\n",
    "        else:\n",
    "            proximo = 0\n",
    "        \n",
    "        lst_recomenda.append((j, \n",
    "                              k['protocolo'], \n",
    "                              k['recomendacao']['sequencia'][j], \n",
    "                              k['recomendacao']['encaminhamento'][j], \n",
    "                              proximo\n",
    "                             )\n",
    "        )\n",
    "\n",
    "    lst_protocolo.append((k['protocolo'], \n",
    "                          k['tempo_medio'], \n",
    "                          prx_acao, \n",
    "                          prx_encaminhamento,\n",
    "                          k['qtd_casos'],\n",
    "                          k['tipo_recomendacao']\n",
    "                         )\n",
    "    )\n",
    "df_protocolo = pd.DataFrame(lst_protocolo)\n",
    "df_recomenda = pd.DataFrame(lst_recomenda)\n",
    "\n",
    "display(df_protocolo)\n",
    "display(df_recomenda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>GRAVA as tabelas de protocolos e recomendações no MySQL</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoadBD - carregando tabelas ... \n",
      "    carregando tabela tb_protocolo ... EXCEPTION - near \")\": syntax error\n"
     ]
    }
   ],
   "source": [
    "# import the module\n",
    "print('LoadBD - carregando tabelas ... ')\n",
    "\n",
    "try:\n",
    "    conn = sqlite3.connect(path_db + ARQ_SQLITE_RECO)\n",
    "    \n",
    "    print('    carregando tabela tb_protocolo ... ', end='')\n",
    "    df_protocolo.to_sql('tb_protocolo', con=conn, if_exists='replace', index=False, chunksize = 10000)\n",
    "    print('OK')\n",
    "\n",
    "    print('    carregando tabela tb_recomenda ... ', end='')\n",
    "    df_recomenda.to_sql('tb_recomenda', con=conn, if_exists='replace', index=False, chunksize = 10000)\n",
    "    print('OK')\n",
    "    \n",
    "except ValueError as vx:\n",
    "    print('ERROR -', vx)\n",
    "\n",
    "except Exception as ex: \n",
    "    print('EXCEPTION -', ex)\n",
    "\n",
    "else:\n",
    "    print('Tabelas criadas com sucesso');  \n",
    "\n",
    "finally:\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
